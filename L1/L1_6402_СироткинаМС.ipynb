{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Установка и настройка окружения"
      ],
      "metadata": {
        "id": "auAoz07eU2XB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCPt0kZUxoto",
        "outputId": "5be45ed5-fb56-46be-817a-5761294fc729"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-09 17:05:47--  https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400446614 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.1-bin-hadoop3.tgz.1’\n",
            "\n",
            "spark-3.5.1-bin-had 100%[===================>] 381.90M  1.25MB/s    in 5m 53s  \n",
            "\n",
            "2025-04-09 17:11:41 (1.08 MB/s) - ‘spark-3.5.1-bin-hadoop3.tgz.1’ saved [400446614/400446614]\n",
            "\n",
            "-rw-r--r-- 1 root root 382M Feb 15  2024 spark-3.5.1-bin-hadoop3.tgz\n"
          ]
        }
      ],
      "source": [
        "# Установка Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Скачивание Spark с выводом статуса (убираем -q для диагностики)\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "# Проверка, что файл загружен\n",
        "!ls -lh spark-3.5.1-bin-hadoop3.tgz || echo \"Ошибка: файл не загружен!\"\n",
        "\n",
        "# Распаковка файла, если он существует\n",
        "!test -f spark-3.5.1-bin-hadoop3.tgz && tar xf spark-3.5.1-bin-hadoop3.tgz || echo \"Пропускаем распаковку: файл отсутствует\"\n",
        "\n",
        "# Установка PySpark\n",
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Устанавливаем переменную окружения JAVA_HOME, указывая путь к Java\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# Импортируем SparkSession для работы с DataFrame API\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum as sql_sum\n",
        "import pyspark.sql.functions as F\n",
        "# Импортируем math для математических вычислений\n",
        "import math\n",
        "# Импортируем udf для создания пользовательских функций в DataFrame\n",
        "from pyspark.sql.functions import udf\n",
        "# Импортируем типы данных для задания схемы\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
        "\n",
        "\n",
        "# Создаем SparkSession — точку входа для работы с Spark\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BikeShareAnalysis\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Получаем SparkContext для работы с RDD\n",
        "sc = spark.sparkContext\n",
        "# Выводим версию Spark для проверки\n",
        "print(f\"Spark version: {spark.version}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okElAZSezCwC",
        "outputId": "98137642-938a-4191-d00e-6d5fccfb6ab9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверяем количество строк в файлах для диагностики\n",
        "print(\"Количество строк в файлах:\")\n",
        "!wc -l /content/trip.csv\n",
        "!wc -l /content/station.csv\n",
        "print(\"Размер файла trip.csv:\")\n",
        "!ls -lh /content/trip.csv\n",
        "\n",
        "# Определяем схему для trip.csv\n",
        "trip_schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"duration\", IntegerType(), True),\n",
        "    StructField(\"start_date\", StringType(), True),\n",
        "    StructField(\"start_station_name\", StringType(), True),\n",
        "    StructField(\"start_station_id\", IntegerType(), True),\n",
        "    StructField(\"end_date\", StringType(), True),\n",
        "    StructField(\"end_station_name\", StringType(), True),\n",
        "    StructField(\"end_station_id\", IntegerType(), True),\n",
        "    StructField(\"bike_id\", IntegerType(), True),\n",
        "    StructField(\"subscription_type\", StringType(), True),\n",
        "    StructField(\"zip_code\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Определяем схему для station.csv\n",
        "station_schema = StructType([\n",
        "    StructField(\"id\", IntegerType(), True),\n",
        "    StructField(\"name\", StringType(), True),\n",
        "    StructField(\"lat\", DoubleType(), True),\n",
        "    StructField(\"long\", DoubleType(), True),\n",
        "    StructField(\"dock_count\", IntegerType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"installation_date\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Загружаем данные из trip.csv в DataFrame без заголовка\n",
        "trip_df = spark.read.schema(trip_schema) \\\n",
        "    .option(\"mode\", \"PERMISSIVE\") \\\n",
        "    .csv(\"/content/trip.csv\")\n",
        "\n",
        "# Удаляем первую строку (заголовок)\n",
        "trip_df = trip_df.filter(col(\"id\").cast(\"int\").isNotNull())\n",
        "\n",
        "# Загружаем данные из station.csv в DataFrame без заголовка\n",
        "station_df = spark.read.schema(station_schema) \\\n",
        "    .option(\"mode\", \"PERMISSIVE\") \\\n",
        "    .csv(\"/content/station.csv\")\n",
        "\n",
        "# Удаляем первую строку (заголовок)\n",
        "station_df = station_df.filter(col(\"id\").cast(\"int\").isNotNull())\n",
        "\n",
        "# Выводим первые 5 строк trip.csv для проверки данных\n",
        "print(\"Первые 5 строк trip.csv:\")\n",
        "trip_df.show(5)\n",
        "\n",
        "# Выводим первые 5 строк station.csv для проверки данных\n",
        "print(\"Первые 5 строк station.csv:\")\n",
        "station_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhLKjJj71ajd",
        "outputId": "2e4e8a27-1d4e-4a2d-82c1-a9f2b99ad6ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество строк в файлах:\n",
            "669960 /content/trip.csv\n",
            "71 /content/station.csv\n",
            "Размер файла trip.csv:\n",
            "-rw-r--r-- 1 root root 77M Apr  9 14:22 /content/trip.csv\n",
            "Первые 5 строк trip.csv:\n",
            "+----+--------+---------------+--------------------+----------------+---------------+--------------------+--------------+-------+-----------------+--------+\n",
            "|  id|duration|     start_date|  start_station_name|start_station_id|       end_date|    end_station_name|end_station_id|bike_id|subscription_type|zip_code|\n",
            "+----+--------+---------------+--------------------+----------------+---------------+--------------------+--------------+-------+-----------------+--------+\n",
            "|4576|      63|8/29/2013 14:13|South Van Ness at...|              66|8/29/2013 14:14|South Van Ness at...|            66|    520|       Subscriber|   94127|\n",
            "|4607|      70|8/29/2013 14:42|  San Jose City Hall|              10|8/29/2013 14:43|  San Jose City Hall|            10|    661|       Subscriber|   95138|\n",
            "|4130|      71|8/29/2013 10:16|Mountain View Cit...|              27|8/29/2013 10:17|Mountain View Cit...|            27|     48|       Subscriber|   97214|\n",
            "|4251|      77|8/29/2013 11:29|  San Jose City Hall|              10|8/29/2013 11:30|  San Jose City Hall|            10|     26|       Subscriber|   95060|\n",
            "|4299|      83|8/29/2013 12:02|South Van Ness at...|              66|8/29/2013 12:04|      Market at 10th|            67|    319|       Subscriber|   94103|\n",
            "+----+--------+---------------+--------------------+----------------+---------------+--------------------+--------------+-------+-----------------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Первые 5 строк station.csv:\n",
            "+---+--------------------+------------------+-------------------+----------+--------+-----------------+\n",
            "| id|                name|               lat|               long|dock_count|    city|installation_date|\n",
            "+---+--------------------+------------------+-------------------+----------+--------+-----------------+\n",
            "|  2|San Jose Diridon ...|         37.329732|-121.90178200000001|        27|San Jose|         8/6/2013|\n",
            "|  3|San Jose Civic Ce...|         37.330698|        -121.888979|        15|San Jose|         8/5/2013|\n",
            "|  4|Santa Clara at Al...|         37.333988|        -121.894902|        11|San Jose|         8/6/2013|\n",
            "|  5|    Adobe on Almaden|         37.331415|          -121.8932|        19|San Jose|         8/5/2013|\n",
            "|  6|    San Pedro Square|37.336721000000004|        -121.894074|        15|San Jose|         8/7/2013|\n",
            "+---+--------------------+------------------+-------------------+----------+--------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 1 — Найти велосипед с максимальным временем пробега"
      ],
      "metadata": {
        "id": "r_HGUOW-YHJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RDD подход\n",
        "trip_rdd = trip_df.rdd\n",
        "bike_duration_rdd = trip_rdd.map(lambda x: (x[\"bike_id\"], x[\"duration\"]))\n",
        "total_bike_duration_rdd = bike_duration_rdd.reduceByKey(lambda a, b: a + b)\n",
        "max_bike_rdd = total_bike_duration_rdd.takeOrdered(1, key=lambda x: -x[1])[0]\n",
        "\n",
        "max_bike_rdd_df = spark.createDataFrame(\n",
        "    [(max_bike_rdd[0], max_bike_rdd[1])],\n",
        "    [\"bike_id\", \"duration\"]\n",
        ")\n",
        "print(\"Задание 1: Велосипед с максимальным временем пробега (RDD):\")\n",
        "max_bike_rdd_df.show()\n",
        "\n",
        "# DataFrame подход\n",
        "max_bike_df = trip_df.groupBy(\"bike_id\") \\\n",
        "    .agg(sql_sum(\"duration\").alias(\"duration\")) \\\n",
        "    .orderBy(col(\"duration\").desc()) \\\n",
        "    .limit(1)\n",
        "\n",
        "print(\"Задание 1: Велосипед с максимальным временем пробега (DataFrame):\")\n",
        "max_bike_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXOqUBfK2xpt",
        "outputId": "b9a39ddc-90b4-4032-9800-75fa7aac362e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задание 1: Велосипед с максимальным временем пробега (RDD):\n",
            "+-------+--------+\n",
            "|bike_id|duration|\n",
            "+-------+--------+\n",
            "|    535|18611693|\n",
            "+-------+--------+\n",
            "\n",
            "Задание 1: Велосипед с максимальным временем пробега (DataFrame):\n",
            "+-------+--------+\n",
            "|bike_id|duration|\n",
            "+-------+--------+\n",
            "|    535|18611693|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 2 — Найти наибольшее геодезическое расстояние между станциями"
      ],
      "metadata": {
        "id": "nKWjjpLUYcJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем функцию для вычисления геодезического расстояния (формула Хаверсина)\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371\n",
        "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "    return R * c\n",
        "\n",
        "# RDD подход\n",
        "stations_rdd = station_df.rdd\n",
        "station_pairs = stations_rdd.cartesian(stations_rdd)\n",
        "station_pairs = station_pairs.filter(lambda x: x[0][\"id\"] < x[1][\"id\"])\n",
        "distances_rdd = station_pairs.map(lambda x: (\n",
        "    (x[0][\"id\"], x[1][\"id\"]),\n",
        "    haversine(x[0][\"lat\"], x[0][\"long\"], x[1][\"lat\"], x[1][\"long\"])\n",
        "))\n",
        "max_distance_rdd = distances_rdd.takeOrdered(1, key=lambda x: -x[1])[0]\n",
        "\n",
        "max_distance_rdd_df = spark.createDataFrame(\n",
        "    [(max_distance_rdd[0][0], max_distance_rdd[0][1], max_distance_rdd[1])],\n",
        "    [\"station_id_1\", \"station_id_2\", \"distance_km\"]\n",
        ")\n",
        "print(\"Задание 2: Наибольшее геодезическое расстояние между станциями (RDD):\")\n",
        "max_distance_rdd_df.show()\n",
        "\n",
        "# DataFrame подход\n",
        "haversine_udf = udf(haversine, DoubleType())\n",
        "station_pairs_df = station_df.alias(\"s1\").crossJoin(station_df.alias(\"s2\"))\n",
        "station_pairs_df = station_pairs_df.filter(col(\"s1.id\") < col(\"s2.id\"))\n",
        "station_pairs_df = station_pairs_df.select(\n",
        "    col(\"s1.id\").alias(\"station_id_1\"),\n",
        "    col(\"s2.id\").alias(\"station_id_2\"),\n",
        "    haversine_udf(col(\"s1.lat\"), col(\"s1.long\"), col(\"s2.lat\"), col(\"s2.long\")).alias(\"distance_km\")\n",
        ")\n",
        "max_distance_df = station_pairs_df.orderBy(col(\"distance_km\").desc()).limit(1)\n",
        "\n",
        "print(\"Задание 2: Наибольшее геодезическое расстояние между станциями (DataFrame):\")\n",
        "max_distance_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX1hcMFr3t98",
        "outputId": "b35144b5-2045-40d9-9da5-2936757cac67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задание 2: Наибольшее геодезическое расстояние между станциями (RDD):\n",
            "+------------+------------+-----------------+\n",
            "|station_id_1|station_id_2|      distance_km|\n",
            "+------------+------------+-----------------+\n",
            "|          16|          60|69.92087595428183|\n",
            "+------------+------------+-----------------+\n",
            "\n",
            "Задание 2: Наибольшее геодезическое расстояние между станциями (DataFrame):\n",
            "+------------+------------+-----------------+\n",
            "|station_id_1|station_id_2|      distance_km|\n",
            "+------------+------------+-----------------+\n",
            "|          16|          60|69.92087595428183|\n",
            "+------------+------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 3 — Найти путь велосипеда с максимальным временем пробега через станции"
      ],
      "metadata": {
        "id": "nMC9m18SYuHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_bike_id = max_bike_df.first()[\"bike_id\"]\n",
        "bike_path_df = trip_df.filter(col(\"bike_id\") == max_bike_id)\n",
        "bike_path_df = bike_path_df.select(\n",
        "    \"start_station_id\",\n",
        "    \"end_station_id\",\n",
        "    \"start_date\",\n",
        "    \"duration\"\n",
        ").orderBy(\"start_date\")\n",
        "\n",
        "print(f\"Задание 3: Путь велосипеда с максимальным временем пробега (ID {max_bike_id}):\")\n",
        "bike_path_df.show(10)\n",
        "print(f\"Количество поездок для велосипеда ID {max_bike_id}: {bike_path_df.count()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0hvj4LZ-ijz",
        "outputId": "b147b493-784d-450d-ee07-8bcddb95356d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задание 3: Путь велосипеда с максимальным временем пробега (ID 535):\n",
            "+----------------+--------------+---------------+--------+\n",
            "|start_station_id|end_station_id|     start_date|duration|\n",
            "+----------------+--------------+---------------+--------+\n",
            "|              75|            60| 1/1/2014 13:42|    3289|\n",
            "|              60|            76| 1/1/2014 18:51|    1286|\n",
            "|              76|            66| 1/1/2014 19:48|     795|\n",
            "|              67|            39|1/10/2014 20:13|     235|\n",
            "|              51|            70| 1/10/2014 8:09|     596|\n",
            "|              70|            55| 1/10/2014 8:21|     600|\n",
            "|              55|            67| 1/10/2014 9:19|     802|\n",
            "|              39|            67|1/11/2014 19:06|     336|\n",
            "|              67|            76|1/12/2014 12:21|     480|\n",
            "|              76|            70|1/12/2014 17:36|    1309|\n",
            "+----------------+--------------+---------------+--------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Количество поездок для велосипеда ID 535: 1328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 4 — Найти количество велосипедов в системе"
      ],
      "metadata": {
        "id": "Z2ndzFI1ZFOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RDD подход\n",
        "bike_ids_rdd = trip_df.rdd.map(lambda x: x[\"bike_id\"])\n",
        "unique_bikes_rdd = bike_ids_rdd.distinct()\n",
        "bike_count_rdd = unique_bikes_rdd.count()\n",
        "\n",
        "bike_count_rdd_df = spark.createDataFrame(\n",
        "    [(bike_count_rdd,)],\n",
        "    [\"total_bikes\"]\n",
        ")\n",
        "print(\"Задание 4: Количество велосипедов в системе (RDD):\")\n",
        "bike_count_rdd_df.show()\n",
        "\n",
        "\n",
        "# DataFrame подход\n",
        "bike_count_df = trip_df.select(\"bike_id\").distinct().count()\n",
        "\n",
        "bike_count_df_df = spark.createDataFrame(\n",
        "    [(bike_count_df,)],\n",
        "    [\"total_bikes\"]\n",
        ")\n",
        "print(\"Задание 4: Количество велосипедов в системе (DataFrame):\")\n",
        "bike_count_df_df.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqhajZdKDSSN",
        "outputId": "256ae444-5af3-40ae-cd67-9f33103fc82b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задание 4: Количество велосипедов в системе (RDD):\n",
            "+-----------+\n",
            "|total_bikes|\n",
            "+-----------+\n",
            "|        700|\n",
            "+-----------+\n",
            "\n",
            "Задание 4: Количество велосипедов в системе (DataFrame):\n",
            "+-----------+\n",
            "|total_bikes|\n",
            "+-----------+\n",
            "|        700|\n",
            "+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задание 5 — Найти пользователей, потративших на поездки более 3 часов"
      ],
      "metadata": {
        "id": "K1fpJxKVZMDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "three_hours = 3 * 3600  # 3 часа = 10,800 секунд\n",
        "\n",
        "# Загружаем station.csv, чтобы получить список корректных station_id\n",
        "station_df = spark.read.schema(station_schema).option(\"mode\", \"PERMISSIVE\").csv(\"/content/station.csv\")\n",
        "station_df = station_df.filter(col(\"id\").cast(\"int\").isNotNull())\n",
        "valid_station_ids = station_df.select(\"id\").distinct().rdd.map(lambda x: x[\"id\"]).collect()\n",
        "\n",
        "# Фильтрация данных\n",
        "trip_df_filtered = trip_df.filter((col(\"duration\") >= 60) & (col(\"duration\") <= 24*3600)) \\\n",
        "    .filter(col(\"zip_code\").isNotNull()) \\\n",
        "    .filter(F.length(col(\"zip_code\")) == 5) \\\n",
        "    .filter(col(\"zip_code\").cast(\"int\").isNotNull()) \\\n",
        "    .filter(col(\"zip_code\").startswith(\"9\")) \\\n",
        "    .filter(col(\"start_station_id\").isin(valid_station_ids)) \\\n",
        "    .filter(col(\"end_station_id\").isin(valid_station_ids)) \\\n",
        "    .filter(col(\"subscription_type\").isin([\"Subscriber\", \"Customer\"])) \\\n",
        "    .filter(F.year(F.to_timestamp(col(\"start_date\"), \"M/d/yyyy H:mm\")).between(2013, 2015)) \\\n",
        "    .dropDuplicates([\"id\"])\n",
        "\n",
        "# DataFrame подход\n",
        "user_duration_df = trip_df_filtered.groupBy(\"zip_code\") \\\n",
        "    .agg(sql_sum(\"duration\").alias(\"total_duration\"))\n",
        "user_duration_df = user_duration_df.filter(col(\"total_duration\") > three_hours) \\\n",
        "    .orderBy(col(\"total_duration\").desc())  # Сортировка по total_duration в убывающем порядке\n",
        "user_count_df = user_duration_df.count()\n",
        "\n",
        "# Проверяем zip_code, которые не достигли порога в 3 часа\n",
        "under_three_hours_df = trip_df_filtered.groupBy(\"zip_code\") \\\n",
        "    .agg(sql_sum(\"duration\").alias(\"total_duration\")) \\\n",
        "    .filter(col(\"total_duration\") <= three_hours)\n",
        "\n",
        "user_count_df_df = spark.createDataFrame(\n",
        "    [(user_count_df,)],\n",
        "    [\"users_over_3_hours\"]\n",
        ")\n",
        "\n",
        "print(\"Задание 5: Первые 15 zip-кодов с временем более 3 часов (DataFrame):\")\n",
        "user_duration_df.show(15)\n",
        "\n",
        "\n",
        "# RDD подход\n",
        "user_duration_rdd = trip_df_filtered.rdd.map(lambda x: (x[\"zip_code\"], x[\"duration\"]))\n",
        "user_duration_rdd = user_duration_rdd.reduceByKey(lambda a, b: a + b)\n",
        "user_duration_rdd = user_duration_rdd.filter(lambda x: x[1] > three_hours) \\\n",
        "    .sortBy(lambda x: x[1], ascending=False)  # Сортировка по total_duration в убывающем порядке\n",
        "user_count_rdd = user_duration_rdd.count()\n",
        "\n",
        "user_count_rdd_df = spark.createDataFrame(\n",
        "    [(user_count_rdd,)],\n",
        "    [\"users_over_3_hours\"]\n",
        ")\n",
        "\n",
        "user_duration_rdd_list = user_duration_rdd.take(15)\n",
        "user_duration_rdd_df = spark.createDataFrame(\n",
        "    user_duration_rdd_list,\n",
        "    [\"zip_code\", \"total_duration_seconds\"]\n",
        ")\n",
        "print(\"Задание 5: Первые 15 zip-кодов с временем более 3 часов (RDD):\")\n",
        "user_duration_rdd_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKEjuwoeNIOF",
        "outputId": "2a0928d3-a292-42cf-e708-f9bb33ed987d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задание 5: Первые 15 zip-кодов с временем более 3 часов (DataFrame):\n",
            "+--------+--------------+\n",
            "|zip_code|total_duration|\n",
            "+--------+--------------+\n",
            "|   94107|      48582326|\n",
            "|   94105|      24834030|\n",
            "|   94133|      21010654|\n",
            "|   94103|      18197645|\n",
            "|   94102|      16543128|\n",
            "|   94111|      13870729|\n",
            "|   94109|      11917431|\n",
            "|   95112|      10150013|\n",
            "|   94110|       6579292|\n",
            "|   94117|       6392830|\n",
            "|   94040|       6248265|\n",
            "|   94158|       6111822|\n",
            "|   94025|       5178237|\n",
            "|   94108|       4996850|\n",
            "|   94041|       4989816|\n",
            "+--------+--------------+\n",
            "only showing top 15 rows\n",
            "\n",
            "Задание 5: Первые 15 zip-кодов с временем более 3 часов (RDD):\n",
            "+--------+----------------------+\n",
            "|zip_code|total_duration_seconds|\n",
            "+--------+----------------------+\n",
            "|   94107|              48582326|\n",
            "|   94105|              24834030|\n",
            "|   94133|              21010654|\n",
            "|   94103|              18197645|\n",
            "|   94102|              16543128|\n",
            "|   94111|              13870729|\n",
            "|   94109|              11917431|\n",
            "|   95112|              10150013|\n",
            "|   94110|               6579292|\n",
            "|   94117|               6392830|\n",
            "|   94040|               6248265|\n",
            "|   94158|               6111822|\n",
            "|   94025|               5178237|\n",
            "|   94108|               4996850|\n",
            "|   94041|               4989816|\n",
            "+--------+----------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}