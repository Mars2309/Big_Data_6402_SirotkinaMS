**Лабораторная работа 1: Введение в MapReduce с Apache Spark**
В данной лабораторной работе изучается фреймворк Apache Spark для обработки больших данных в распределённой среде. Работа выполнена в среде Google Colab на языке Python с использованием API DataFrame и RDD. Код представлен в файле LR1_BigData.ipynb.

**Цели работы**
Освоить базовые операции обработки данных в Spark.
Решить задачи анализа данных на основе датасета велопарковок Сан-Франциско.
Используемые данные
Датасет: SF Bay Area Bike Share
Файлы: trips.csv (поездки) и stations.csv (станции).


**Решите следующие задачи для данных велопарковок Сан-Франциско (trips.csv, stations.csv):**

1. Найти велосипед с максимальным временем пробега.
2. Найти наибольшее геодезическое расстояние между станциями.
3. Найти путь велосипеда с максимальным временем пробега через станции.
4. Найти количество велосипедов в системе.
5. Найти пользователей потративших на поездки более 3 часов.

Работа была выполнена в Google Collab.

Сироткина Маргарита 6402
